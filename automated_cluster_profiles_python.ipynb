{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataiku\n",
    "from dataiku import pandasutils as pdu\n",
    "import pandas as pd\n",
    "\n",
    "df = dataiku.Dataset(\"features_by_segment_and_uid\").get_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTEBOOK PURPOSE AND INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataframe derived from a clustering method (e.g. Kmeans) the below script is an automated script to profile the cluster groups according to the attached features. \n",
    "\n",
    "The script will automatically determine which features are categorical, one-hot encode them and then calculate the % of the cluster that are within each category.\n",
    "\n",
    "It will also determine which features are continuous and calculate averages across the cluster group.\n",
    "\n",
    "The input file requires each record to be a unique ID, with a single column designating its cluster group. As many additional features / columns as desired can be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_function(dataframe, indexfield, groupbyfield):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ---------- \n",
    "        dataframe : pd.DataFrame\n",
    "            the dataframe to use  \n",
    "        indexfield: string\n",
    "            the name of the unique identifier column\n",
    "        groupbyfield: string\n",
    "            the names or codes of the cluster the unique record is allocated to\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    pd.DataFramecolumns\n",
    "            dataframe with a record for each unique cluster group, along with a set of columns that are either averages\n",
    "            of continuous input features, or % of group categories for categorical features\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    # Onehot encode items in categorical_list\n",
    "\n",
    "    # Get list of categorical features\n",
    "    categorical_list = [key for key in dict(dataframe.dtypes)\n",
    "                        if (dict(dataframe.dtypes)[key] in ['object'])\n",
    "                        and (len(dataframe.loc[lambda x: x[key].isin(['1', '0', '1.0', '0.0']),:])) == 0\n",
    "                        and key != groupbyfield]\n",
    "\n",
    "    print (\"Categorical Features for Encoding: \", categorical_list, '\\n')\n",
    "\n",
    "    for item in categorical_list:\n",
    "        cat_feature = dataframe[[item]]\n",
    "\n",
    "        cat_feature_encoded = (pd.get_dummies(cat_feature, prefix='', prefix_sep='')\n",
    "                               .max(level=0, axis=1)\n",
    "                               .add_prefix(item+' - '))\n",
    "\n",
    "        # add the one-hot encoded column to the dataframe\n",
    "        dataframe = pd.concat([dataframe, cat_feature_encoded], axis=1)\n",
    "\n",
    "        # remove the original columns\n",
    "        dataframe = dataframe.drop([item], axis=1)\n",
    "\n",
    "    # Change columns that should be booleans to be so (from float and int)\n",
    "    bool_fix_list = [key for key in dict(dataframe.dtypes)\n",
    "                if (len(dataframe.loc[lambda x: x[key].isin([1, 1.0]),:])\n",
    "                    + len(dataframe.loc[lambda x: x[key].isin([0, 0.0]),:])\n",
    "                    == len(dataframe))]\n",
    "    dataframe[bool_fix_list] = dataframe[bool_fix_list].astype(bool)\n",
    "\n",
    "    # Create a dictionary of variables by type to aggregate up by ClusterID\n",
    "    agg_dictionary = {}\n",
    "    avg_list = []\n",
    "    bool_list = []\n",
    "    for col in dataframe:\n",
    "        if (dict(dataframe.dtypes)[col] in ['int64', 'float64']) and col not in [indexfield, groupbyfield]:\n",
    "            agg_dictionary[col] = 'mean'\n",
    "            avg_list.append(col)\n",
    "        if (dict(dataframe.dtypes)[col] in ['bool']) and col not in [indexfield, groupbyfield]:\n",
    "            agg_dictionary[col] = 'sum'\n",
    "            bool_list.append(col)\n",
    "\n",
    "    agg_dictionary[indexfield] = 'nunique'\n",
    "\n",
    "    print ('Boolean Features: ', bool_list, '\\n')\n",
    "    print ('Continuous Features: ', avg_list, '\\n')\n",
    "\n",
    "    # Groupby ClusterID\n",
    "    print ('Grouping by: ', groupbyfield)\n",
    "    dataframe = dataframe.groupby(groupbyfield).agg(agg_dictionary).reset_index()\n",
    "\n",
    "    # Turn absolute values into % values by cluster\n",
    "    dataframe[bool_list] = dataframe[bool_list].div(dataframe[indexfield], axis=0) * 100\n",
    "\n",
    "    # Round all pct columns to be 4 decimal places\n",
    "    dataframe[avg_list] = round(dataframe[avg_list],4)\n",
    "    dataframe[bool_list] = dataframe[bool_list].astype(float)\n",
    "    dataframe[bool_list] = round(dataframe[bool_list],4)\n",
    "\n",
    "    # Rename columns according to whether they are avg or pct columns\n",
    "    rename_list = {**{col: col + '_avg' for col in avg_list}\n",
    "                   ,**{col: col + '_pct' for col in bool_list}\n",
    "                   ,**{indexfield: 'num_' + indexfield}\n",
    "                  }\n",
    "    dataframe.rename(columns=rename_list, inplace=True)\n",
    "\n",
    "    # Create population size column\n",
    "    dataframe[indexfield + '_pct'] = round((dataframe['num_' + indexfield]\n",
    "                                            / sum(dataframe['num_' + indexfield]) * 100),4)\n",
    "\n",
    "    # Move indexfield columns to front of dataframe\n",
    "    cols = list(dataframe)\n",
    "    cols.insert(1, cols.pop(cols.index('num_' + indexfield)))\n",
    "    cols.insert(2, cols.pop(cols.index(indexfield + '_pct')))\n",
    "    dataframe = dataframe[cols]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = profile_function(df, 'unique_identifier', 'Cluster_Code')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
